import google.generativeai as genai
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
import joblib
import os
import json
import re
from datetime import datetime

class NewsProcessorCompleto:
    def __init__(self):
        # DEFINA OS ATRIBUTOS PRIMEIRO
        self.model_file = "relevance_model.pkl"
        self.vectorizer_file = "vectorizer.pkl" 
        self.feedback_file = "feedback.csv"
        self.data_file = "database/news_database.json"
        
        
        self.KEYWORDS = [
            "Brasil", "brasileiro", "portos brasileiros", "S√£o Lu√≠s", "Fortaleza", 
            "Macap√°", "Bel√©m", "Maranh√£o", "Cear√°", "Amap√°", "Par√°", "Norte", "Nordeste",
            "ANTAQ", "Marinha do Brasil", "Minist√©rio dos Transportes", "porto de Itaqui",
            "porto do Pec√©m", "porto de Suape", "navio brasileiro", "carga mar√≠tima",
            "seguro mar√≠timo", "sinistro naval", "regulamenta√ß√£o portu√°ria", "despacho aduaneiro",
            "taxa portu√°ria", "alf√¢ndega", "cabotagem", "offshore", "hidrovia"
        ]
        
        self.NEGATIVE_KEYWORDS = ["global", "internacional", "EUA", "China", "Europa", "hist√≥rico", "antigo"]
        
        # AGORA configura os sistemas
        self.setup_gemini()
        self.setup_ml_system()
    
    def setup_gemini(self):
        """Configura Gemini 2.5"""
        api_key = os.getenv("GEMINI_API_KEY")
        if api_key and api_key != "sua_chave_gemini_aqui":
            try:
                genai.configure(api_key=api_key)
                self.model_flash = genai.GenerativeModel('gemini-2.0-flash')
                self.gemini_enabled = True
                print("‚úÖ Gemini 2.5 Flash Configurado")
            except Exception as e:
                print(f"‚ùå Erro configurando Gemini: {e}")
                self.gemini_enabled = False
        else:
            self.gemini_enabled = False
            print("‚ö†Ô∏è Gemini n√£o configurado")
    
    def setup_ml_system(self):
        """Sistema de ML do SEU processor.py original"""
        self.ml_model, self.ml_vectorizer = self.load_ml_model()
        if self.ml_model is None:
            print("üîß Treinando modelo ML...")
            self.ml_model, self.ml_vectorizer = self.train_ml_model()
    
    def executar_coleta_completa(self):
        """Executa processamento COMPLETO mantendo todas as funcionalidades"""
        print("üöÄ INICIANDO PROCESSAMENTO COMPLETO BRAZMAR")
        
        
        try:
            from scraper import fetch_rss, fetch_scrape
            artigos_rss = fetch_rss()
            artigos_scrape = fetch_scrape()
            artigos = artigos_rss + artigos_scrape
            print(f"üì∞ {len(artigos)} not√≠cias coletadas")
        except Exception as e:
            print(f"‚ùå Erro na coleta: {e}")
            return []
        
        # 2. PR√â-PROCESSAMENTO
        artigos_processados = self.preprocessar_artigos(artigos)
        
        # 3. FILTRAGEM H√çBRIDA (ML original + Gemini novo)
        artigos_relevantes = self.filtrar_artigos(artigos_processados)
        print(f"‚úÖ {len(artigos_relevantes)} not√≠cias relevantes encontradas")
        
        # 4. SALVAR NO DATABASE
        self.salvar_no_database(artigos_relevantes)
        
        return artigos_relevantes
    
    def preprocessar_artigos(self, artigos):
        """Pr√©-processamento do SEU original"""
        artigos_processados = []
        
        for artigo in artigos:
            processed_artigo = artigo.copy()
            
            # Garante campos obrigat√≥rios
            processed_artigo['title'] = processed_artigo.get('title', 'No Title').strip()
            processed_artigo['summary'] = processed_artigo.get('summary', '').strip()
            processed_artigo['source'] = processed_artigo.get('source', 'Unknown').strip()
            
            # Limpeza b√°sica
            processed_artigo['summary'] = re.sub(r'http\S+', '', processed_artigo['summary'])
            processed_artigo['summary'] = ' '.join(processed_artigo['summary'].split())
            
            # Se summary muito curto, usa t√≠tulo como fallback
            if len(processed_artigo['summary']) < 20:
                processed_artigo['summary'] = processed_artigo['title']
            
            artigos_processados.append(processed_artigo)
        
        return artigos_processados
    
    def filtrar_artigos(self, artigos):
        """Filtragem H√çBRIDA (ML original + Gemini)"""
        artigos_relevantes = []
        
        for i, artigo in enumerate(artigos):
            print(f"üîç Analisando {i+1}/{len(artigos)}: {artigo['title'][:50]}...")
            
            
            relevante_auto = self.filtro_automatico(artigo)
            
            if not relevante_auto:
                print("   ‚ùå Rejeitado pelo filtro autom√°tico")
                continue
            
            
            relevante_ml = self.filtrar_por_ml(artigo)
            
            if not relevante_ml:
                print("   ‚ùå Rejeitado pelo ML")
                continue
            
            
            if self.gemini_enabled:
                relevante_gemini = self.filtrar_por_gemini(artigo)
                if not relevante_gemini:
                    print("   ‚ùå Rejeitado pelo Gemini")
                    continue
                else:
                    print("   ‚úÖ Aprovado pelo Gemini")
            else:
                print("   ‚úÖ Aprovado pelo ML")
            
            # Adiciona metadados de processamento
            artigo['processed_at'] = datetime.now().isoformat()
            artigo['collection_date'] = datetime.now().strftime("%Y-%m-%d")
            artigo['ai_analyzed'] = self.gemini_enabled
            
            artigos_relevantes.append(artigo)
        
        return artigos_relevantes
    
    def filtro_automatico(self, artigo):
        """SEU filtro autom√°tico original do processor.py"""
        combined_text = (artigo['title'] + " " + artigo['summary']).lower()
        score = sum(1 for kw in self.KEYWORDS if kw.lower() in combined_text)
        
        # Penaliza por negative keywords
        negative_score = sum(1 for nkw in self.NEGATIVE_KEYWORDS if nkw.lower() in combined_text)
        score -= negative_score * 2
        
        print(f"   üîß Score autom√°tico: {score}")
        return score >= 5  
    
    def filtrar_por_ml(self, artigo):
        """SEU sistema de ML original do processor.py"""
        if self.ml_model is None or self.ml_vectorizer is None:
            return True  # Se n√£o tem ML, aprova pelo filtro autom√°tico
        
        try:
            combined_text = artigo['title'] + " " + artigo['summary']
            features = self.ml_vectorizer.transform([combined_text])
            prediction = self.ml_model.predict(features)[0]
            probability = self.ml_model.predict_proba(features)[0][1]
            
            print(f"   ü§ñ ML - Predi√ß√£o: {prediction}, Probabilidade: {probability:.2f}")
            return prediction == 1 and probability > 0.6
            
        except Exception as e:
            print(f"   ‚ùå Erro ML: {e}")
            return True  # Fallback: aprova se ML falhar
    
    def filtrar_por_gemini(self, artigo):
        """Nova funcionalidade com Gemini"""
        try:
            prompt = f"""
            ANALISAR para BRAZMAR MARINE SERVICES (seguros mar√≠timos, consultoria portu√°ria):

            T√çTULO: {artigo['title']}
            RESUMO: {artigo['summary']}

            Esta not√≠cia √© relevante para seguros mar√≠timos ou opera√ß√µes portu√°rias?
            Foco em ANTAQ, portos brasileiros, regulamenta√ß√£o mar√≠tima.

            Responda APENAS com JSON:
            {{
                "relevante": true/false,
                "confianca": 0-100,
                "motivo": "explica√ß√£o curta",
                "urgencia": "BAIXA/MEDIA/ALTA"
            }}
            """
            
            response = self.model_flash.generate_content(prompt)
            analysis = self.parse_resposta_gemini(response.text)
            
            if analysis.get('relevante', False):
                artigo['gemini_analysis'] = analysis
                artigo['confianca'] = analysis.get('confianca', 0)
                artigo['urgencia'] = analysis.get('urgencia', 'BAIXA')
                print(f"   ‚úÖ Gemini - Confian√ßa: {analysis.get('confianca', 0)}%")
                return True
            else:
                print(f"   ‚ùå Gemini - Motivo: {analysis.get('motivo', 'N/A')}")
                return False
                
        except Exception as e:
            print(f"   ‚ùå Erro Gemini: {e}")
            return True  # Fallback: aprova se Gemini falhar
    
    def parse_resposta_gemini(self, response_text):
        """Parse da resposta do Gemini"""
        try:
            cleaned = re.sub(r'```json|```', '', response_text).strip()
            json_match = re.search(r'\{[^}]*\}', cleaned, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except Exception as e:
            print(f"   ‚ùå Erro parse Gemini: {e}")
        
        return {"relevante": False, "confianca": 0, "motivo": "Erro na an√°lise", "urgencia": "BAIXA"}
    
    # M√âTODOS DO SEU SISTEMA DE ML ORIGINAL
    def load_ml_model(self):
        """SEU carregador de ML original do processor.py"""
        if os.path.exists(self.model_file) and os.path.exists(self.vectorizer_file):
            try:
                model = joblib.load(self.model_file)
                vectorizer = joblib.load(self.vectorizer_file)
                print("‚úÖ Modelo ML carregado do cache")
                return model, vectorizer
            except Exception as e:
                print(f"‚ùå Erro carregando ML: {e}")
        return None, None
    
    def train_ml_model(self):
        """SEU treinador de ML original do processor.py"""
        if not os.path.exists(self.feedback_file) or os.path.getsize(self.feedback_file) == 0:
            print("üìä CSV de feedback vazio. ML ser√° treinado posteriormente.")
            return None, None
        
        try:
            df = pd.read_csv(self.feedback_file)
            
            if 'relevant' not in df.columns or len(df) < 2:
                print("‚ö†Ô∏è Dados insuficientes para treinar ML")
                return None, None
            
            df['text'] = df['title'].fillna('') + " " + df['summary'].fillna('')
            texts = df['text'].tolist()
            labels = df['relevant'].astype(bool).tolist()
            
            pipeline = Pipeline([
                ('tfidf', TfidfVectorizer(max_features=1000, stop_words='english')),
                ('clf', LogisticRegression())
            ])
            
            pipeline.fit(texts, labels)
            joblib.dump(pipeline.named_steps['clf'], self.model_file)
            joblib.dump(pipeline.named_steps['tfidf'], self.vectorizer_file)
            print("‚úÖ Modelo ML treinado com feedback")
            return pipeline.named_steps['clf'], pipeline.named_steps['tfidf']
            
        except Exception as e:
            print(f"‚ùå Erro treinamento ML: {e}")
            return None, None
    
    def salvar_no_database(self, artigos):
        """Salva artigos no database JSON"""
        os.makedirs("database", exist_ok=True)
        
        try:
            with open(self.data_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except FileNotFoundError:
            data = {"articles": [], "stats": {}}
        
        # Adiciona novos artigos (evita duplicatas)
        titulos_existentes = {a['title'] for a in data['articles']}
        novos = 0
        
        for artigo in artigos:
            if artigo['title'] not in titulos_existentes:
                # Garante campos essenciais
                if 'confianca' not in artigo:
                    artigo['confianca'] = 50
                if 'urgencia' not in artigo:
                    artigo['urgencia'] = 'BAIXA'
                    
                data['articles'].append(artigo)
                novos += 1
        
        # Mant√©m apenas √∫ltimos 200 artigos
        data['articles'] = data['articles'][-200:]
        
        # Atualiza estat√≠sticas
        hoje = datetime.now().strftime("%Y-%m-%d")
        artigos_hoje = [a for a in data['articles'] if a.get('collection_date') == hoje]
        
        data['stats'] = {
            "total_articles": len(data['articles']),
            "today_articles": len(artigos_hoje),
            "last_updated": datetime.now().isoformat()
        }
        
        data['last_updated'] = datetime.now().isoformat()
        
        with open(self.data_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Database atualizado: {novos} novos artigos (total: {len(data['articles'])})")